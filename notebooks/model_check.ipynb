{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7887c9c06368cb33",
   "metadata": {},
   "source": [
    "# Model Checks\n",
    "\n",
    "In this notebook, we will import and initialise all models to ensure that they are working correctly.\n",
    "This notebook serves as a sanity check to ensure that all models are correctly implemented and can be initialised without any errors.\n",
    "We use the **MNIST Sequential** dataset as a sample dataset to test the models.\n",
    "It does not serve any purpose for training or evaluation.\n",
    "\n",
    "## Initialisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:20:21.912495Z",
     "start_time": "2024-05-21T03:20:20.612656Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Print Python Version & PyTorch version\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "print(f\"Python version\\t=\\t{sys.version}\\nPyTorch version\\t=\\t{torch.__version__}\")\n",
    "# Make torch deterministic\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fece647d912d1da2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:20:21.930592Z",
     "start_time": "2024-05-21T03:20:21.913803Z"
    }
   },
   "outputs": [],
   "source": [
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "if RunningInCOLAB:\n",
    "    # Move to default colab folder\n",
    "    %cd /content\n",
    "    # Check if repository is already cloned\n",
    "    if not os.path.isdir(\"stg\"):\n",
    "        # Clone repository\n",
    "        !git clone {config.GITHUB_URL} {config.MODULE_NAME}\n",
    "    # Change to repository directory\n",
    "    %cd {config.MODULE_NAME}\n",
    "    # Only install requirements not already installed by Colab\n",
    "    # !pip install opacus\n",
    "    # SLOW: Only execute the following line if you encounter an error regarding a package not being installed\n",
    "    # !pip install -r requirements.txt\n",
    "else:\n",
    "    import sys\n",
    "    # Add parent directory (absolute!) to path\n",
    "    sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6025cc23e3d46f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:20:25.046018Z",
     "start_time": "2024-05-21T03:20:21.931683Z"
    }
   },
   "outputs": [],
   "source": [
    "from conv_gan.models.noise_trajgan import Noise_TrajGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc968159ffa1116",
   "metadata": {},
   "source": [
    "## Sample Dataset\n",
    "\n",
    "We use the MNIST Sequential dataset as a sample dataset to test the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e6beb721e7f728",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:20:25.395552Z",
     "start_time": "2024-05-21T03:20:25.047101Z"
    }
   },
   "outputs": [],
   "source": [
    "from conv_gan.datasets.mnist_data import mnist_sequential, show_mnist_samples\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "ds = mnist_sequential(28)\n",
    "# Print Shape of one sample\n",
    "print(f\"Sample:\\t{ds[0][0].shape}\\nLabel:\\t{type(ds[0][1])}\")\n",
    "\n",
    "# Create collate function that drops the label and puts features first\n",
    "def collate_fn(batch) -> torch.Tensor:\n",
    "    batch = torch.stack([b[0] for b in batch])\n",
    "    # Add another feature dimension in the front\n",
    "    batch = batch.unsqueeze(0)\n",
    "    return batch\n",
    "    \n",
    "from torch.utils.data import DataLoader\n",
    "dl = DataLoader(ds, batch_size=BATCH_SIZE, collate_fn=collate_fn)\n",
    "\n",
    "# Print Shape of one batch\n",
    "print(f\"Batch:\\t{next(iter(dl)).shape}\")\n",
    "\n",
    "# Print 25 random samples\n",
    "samples = torch.stack([ds[i][0] for i in range(25)])\n",
    "_ = show_mnist_samples(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835cfaf6b350e359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:20:25.442121Z",
     "start_time": "2024-05-21T03:20:25.398717Z"
    }
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "FEATURES = ['mnist']\n",
    "vocab_size = {'mnist': 28}\n",
    "embedding_size = {'mnist': 64}\n",
    "LATENT_DIM = 256\n",
    "NOISE_DIM = 28\n",
    "GPU = 0\n",
    "\n",
    "# Training Parameters\n",
    "EPOCHS = 10\n",
    "\n",
    "WGAN = True\n",
    "LP = True  # Lipschitz Penalty required!\n",
    "LR_G = 0.0001\n",
    "LR_D = 0.0005\n",
    "N_CRITIC = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95715805df4c5154",
   "metadata": {},
   "source": [
    "## Noise-TrajGAN: Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f872a032d5dd3103",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:20:25.694486Z",
     "start_time": "2024-05-21T03:20:25.444356Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import Noise-TrajGAN\n",
    "from conv_gan.models.noise_trajgan import Noise_TrajGAN\n",
    "\n",
    "name = f'NTG_MNIST_G{LR_G}_{N_CRITIC}xD{LR_D}_L{LATENT_DIM}_N{NOISE_DIM}_B{BATCH_SIZE}_{\"WGAN\" if WGAN else \"GAN\"}'\n",
    "\n",
    "# Create a Noise-TrajGAN model\n",
    "ntg = Noise_TrajGAN(\n",
    "    features=FEATURES,\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=embedding_size,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    noise_dim=NOISE_DIM,\n",
    "    wgan=WGAN,\n",
    "    gradient_penalty=LP,\n",
    "    lipschitz_penalty=LP,\n",
    "    lr_g=LR_G,\n",
    "    lr_d=LR_D,\n",
    "    gpu = 0,\n",
    "    name=name,\n",
    ")\n",
    "# Print and compare feature number of generator and discriminator\n",
    "count_params_torch = lambda model: sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"Generator Parameters:\\t\\t{count_params_torch(ntg.gen)}\")\n",
    "print(f\"Discriminator Parameters:\\t{count_params_torch(ntg.dis)}\")\n",
    "print(f\"Relationship [G / D]:\\t\\t{count_params_torch(ntg.gen) / count_params_torch(ntg.dis) * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e48e7b0c7243e51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:20:26.073017Z",
     "start_time": "2024-05-21T03:20:25.695768Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print an initial output of NTG\n",
    "ntg_output = torch.as_tensor(ntg.generate(25, 28))\n",
    "print(ntg_output.shape)\n",
    "show_mnist_samples(ntg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef3865c8e2a6646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "ntg.training_loop(dl, epochs=EPOCHS, dataset_name='mnist', n_critic=N_CRITIC, plot_freq=30, save_freq=-1, tensorboard=True, notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c4d6c92432926d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:20:49.627316Z",
     "start_time": "2024-05-21T03:20:49.280377Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print an output of NTG after completed Training\n",
    "ntg_output = torch.as_tensor(ntg.generate(25, 28))\n",
    "print(ntg_output.shape)\n",
    "show_mnist_samples(ntg_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d2f36d9efb17a9",
   "metadata": {},
   "source": [
    "## Noise-TrajGAN with Differential Privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cabcdae2430198e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:20:49.688912Z",
     "start_time": "2024-05-21T03:20:49.628632Z"
    }
   },
   "outputs": [],
   "source": [
    "# DP Parameters\n",
    "EPSILON = 10.0\n",
    "ACCOUNTANT = 'prv'  # Default is 'prv', but I found that 'rdp' is more stable in some situation \n",
    "MAX_GRAD_NORM = 0.1\n",
    "# Delta should be 1/n where n is the number of samples according to DPfy-ML\n",
    "DELTA = 1 / len(ds)\n",
    "print(f\"Epsilon:\\t{EPSILON:.1f}\\nDelta:\\t\\t{DELTA:.2e}\\nMax Grad Norm:\\t{MAX_GRAD_NORM}\\nAccountant:\\t{ACCOUNTANT}\")\n",
    "\n",
    "\n",
    "DP_IN_DIS = False  # Whether to apply DP-SGD to discriminator or generator\n",
    "# WGAN Clipping does not work if DP is applied to the discriminator\n",
    "LP = not DP_IN_DIS\n",
    "WGAN = True\n",
    "if not DP_IN_DIS and N_CRITIC > 1:\n",
    "    print(\"Warning: Training with DP and N_CRITIC is a bit of a gamble because we might actually be wasting privacy budget on the discriminator which does not even uses DP.\")\n",
    "\n",
    "# Increase learning rate of DP model to make up for the gradient clipping\n",
    "if DP_IN_DIS:\n",
    "    LR_D = LR_D / MAX_GRAD_NORM \n",
    "else:\n",
    "    LR_G = LR_G / MAX_GRAD_NORM\n",
    "\n",
    "print(f\"LR_G:\\t{LR_G}\\nLR_D:\\t{LR_D}\")\n",
    "\n",
    "# Create new DataLoader\n",
    "# The number of steps should be the same as without DP, but DP-SGD works better for large batches\n",
    "# --> Increase batches and epochs by same factor\n",
    "FACTOR = 10\n",
    "DP_BATCH_SIZE = BATCH_SIZE * FACTOR\n",
    "DP_EPOCHS = EPOCHS * FACTOR\n",
    "dp_dl = DataLoader(ds, batch_size=DP_BATCH_SIZE, collate_fn=collate_fn)\n",
    "print(f\"Batch Size:\\t{DP_BATCH_SIZE}\\nEpochs:\\t\\t{DP_EPOCHS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb251205d0575dc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:20:49.764507Z",
     "start_time": "2024-05-21T03:20:49.696347Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize DP-Noise-TrajGAN\n",
    "name = f'DP-NTG_MNIST_G{LR_G}_{N_CRITIC}xD{LR_D}_L{LATENT_DIM}_N{NOISE_DIM}_B{DP_BATCH_SIZE}_C{MAX_GRAD_NORM}'\n",
    "\n",
    "dp_ntg = Noise_TrajGAN(\n",
    "    features=FEATURES,\n",
    "    vocab_size=vocab_size,\n",
    "    embedding_size=embedding_size,\n",
    "    latent_dim=LATENT_DIM,\n",
    "    noise_dim=NOISE_DIM,\n",
    "    lr_g=LR_G,\n",
    "    lr_d=LR_D,\n",
    "    gpu = 0,\n",
    "    name=name,\n",
    "    wgan=WGAN,\n",
    "    gradient_penalty=LP,\n",
    "    lipschitz_penalty=LP,\n",
    "    dp=True,\n",
    "    dp_in_dis=DP_IN_DIS,\n",
    "    privacy_accountant=ACCOUNTANT\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b3068358dedae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:21:00.961413Z",
     "start_time": "2024-05-21T03:20:49.767286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize DP --> Returns DP dataloader\n",
    "dp_dl = dp_ntg.init_dp(\n",
    "    dataloader=dp_dl,\n",
    "    epochs=DP_EPOCHS,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    "    target_epsilon=EPSILON,\n",
    "    delta=DELTA,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4c14af890303b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:21:01.319375Z",
     "start_time": "2024-05-21T03:21:00.963719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print an initial output of DP-NTG\n",
    "dp_ntg_output = torch.as_tensor(dp_ntg.generate(25, 28))\n",
    "show_mnist_samples(dp_ntg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74470ed99a03aaeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:21:20.010375Z",
     "start_time": "2024-05-21T03:21:18.696325Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the DP Model\n",
    "dp_ntg.training_loop(dp_dl, epochs=DP_EPOCHS, dataset_name='mnist', n_critic=N_CRITIC, plot_freq=200, save_freq=-1, tensorboard=True, notebook=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccf20350af93a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:21:21.748473Z",
     "start_time": "2024-05-21T03:21:21.305936Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print an output of DP-NTG after completed Training\n",
    "dp_ntg_output = torch.as_tensor(dp_ntg.generate(25, 28))\n",
    "show_mnist_samples(dp_ntg_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a947f79e9782f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T03:21:21.953467Z",
     "start_time": "2024-05-21T03:21:21.763258Z"
    }
   },
   "outputs": [],
   "source": [
    "# Print resulting privacy loss\n",
    "print(\"Final Delta:\\t\", dp_ntg.delta)\n",
    "print(\"Final Epsilon:\\t\", dp_ntg.epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b14dc516ec370e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convGAN",
   "language": "python",
   "name": "convgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
