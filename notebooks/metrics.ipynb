{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T02:47:37.971591Z",
     "start_time": "2024-05-21T02:47:34.808002Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "import ot\n",
    "\n",
    "import config\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "# Print Python Version & PyTorch version\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "print(f\"Python version\\t=\\t{sys.version}\\nPyTorch version\\t=\\t{torch.__version__}\")\n",
    "# Make torch deterministic\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86aea2824ee677c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T02:47:38.008291Z",
     "start_time": "2024-05-21T02:47:37.973320Z"
    }
   },
   "outputs": [],
   "source": [
    "RunningInCOLAB = 'google.colab' in str(get_ipython())\n",
    "if RunningInCOLAB:\n",
    "    # Move to default colab folder\n",
    "    %cd /content\n",
    "    # Check if repository is already cloned\n",
    "    if not os.path.isdir(\"stg\"):\n",
    "        # Clone repository\n",
    "        !git clone {config.GITHUB_URL} {config.MODULE_NAME}\n",
    "    # Change to repository directory\n",
    "    %cd {config.MODULE_NAME}\n",
    "    # Only install requirements not already installed by Colab\n",
    "    # !pip install opacus\n",
    "    # SLOW: Only execute the following line if you encounter an error regarding a package not being installed\n",
    "    # !pip install -r requirements.txt\n",
    "else:\n",
    "    import sys\n",
    "    # Add parent directory (absolute!) to path\n",
    "    sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def507195028b939",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T02:47:40.140681Z",
     "start_time": "2024-05-21T02:47:38.009348Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generate two distributions of 2D points\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "n_samples = 100000\n",
    "n_features = 2\n",
    "\n",
    "S = np.random.randn(n_samples, n_features)\n",
    "T = np.random.randn(n_samples, n_features) + (2, 1)\n",
    "U = np.random.randn(n_samples, n_features) + (4, 2)\n",
    "\n",
    "\n",
    "# smaller markersize\n",
    "plt.scatter(S[:, 0], S[:, 1], label='S', s=1)\n",
    "plt.scatter(T[:, 0], T[:, 1], label='T', s=1)\n",
    "plt.scatter(U[:, 0], U[:, 1], label='U', s=1)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17acfabb85e128",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T02:47:49.796143Z",
     "start_time": "2024-05-21T02:47:40.141947Z"
    }
   },
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "# The best case is the sliced WD, but very slow\n",
    "start = timer()\n",
    "swd_st = ot.sliced_wasserstein_distance(S, T)\n",
    "end = timer()\n",
    "print(f\"Sliced Wasserstein distance between S and T: {swd_st:.2f} in {end-start:.2f} seconds\")\n",
    "\n",
    "swd_ss = ot.sliced_wasserstein_distance(S, S)\n",
    "swd_su = ot.sliced_wasserstein_distance(S, U)\n",
    "\n",
    "print(f\"Sliced Wasserstein distance between S and S: {swd_ss:.2f}\")\n",
    "print(f\"Sliced Wasserstein distance between S and U: {swd_su:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adde61231ebeef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T02:47:50.819461Z",
     "start_time": "2024-05-21T02:47:49.798124Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now, we repeat by sampling 10k points from each distribution as compare\n",
    "n_samples = 10000\n",
    "S_small = S[np.random.choice(S.shape[0], n_samples, replace=False)]\n",
    "T_small = T[np.random.choice(T.shape[0], n_samples, replace=False)]\n",
    "U_small = U[np.random.choice(U.shape[0], n_samples, replace=False)]\n",
    "\n",
    "swd_st_small = ot.sliced_wasserstein_distance(S_small, T_small)\n",
    "swd_ss_small = ot.sliced_wasserstein_distance(S_small, S_small)\n",
    "swd_su_small = ot.sliced_wasserstein_distance(S_small, U_small)\n",
    "\n",
    "print(f\"Sliced Wasserstein distance between S and T: {swd_st_small:.2f};\\t Difference: {swd_st_small-swd_st:.2f}\")\n",
    "print(f\"Sliced Wasserstein distance between S and S: {swd_ss_small:.2f};\\t Difference: {swd_ss_small-swd_ss:.2f}\")\n",
    "print(f\"Sliced Wasserstein distance between S and U: {swd_su_small:.2f};\\t Difference: {swd_su_small-swd_su:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94261dc0b81b9e7c",
   "metadata": {},
   "source": [
    "## Try on Foursquare how much our results will be off if we only consider 10'000 points instead of the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3902e5059b5b8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T02:47:53.015727Z",
     "start_time": "2024-05-21T02:47:50.830243Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from conv_gan.datasets import get_dataset, Datasets\n",
    "# Load FS\n",
    "fs_ds = get_dataset(Datasets.FS)\n",
    "print(\"Total Trajectories:\\t\\t\\t\", len(fs_ds), \"\\nFeatures per Trajectory:\\t\", len(fs_ds[0]), \"\\nShape of one location traj:\\t\", fs_ds[0][0].shape)\n",
    "# Create a point dataset\n",
    "trajs = [t[0] for t in fs_ds]\n",
    "# Concatenate along dim 0\n",
    "points = torch.cat(trajs, dim=0).numpy()\n",
    "print(\"Total Points:\\t\\t\\t\\t\", points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709e20a0561a8846",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T02:47:55.401752Z",
     "start_time": "2024-05-21T02:47:53.016809Z"
    }
   },
   "outputs": [],
   "source": [
    "# Compute SWD of entire dataset and of 10k points\n",
    "fake = np.random.randn(points.shape[0], points.shape[1])\n",
    "swd_fs = ot.sliced_wasserstein_distance(points, fake)\n",
    "print(f\"Sliced Wasserstein distance between FS and random: {swd_fs:.5f}\")\n",
    "\n",
    "n_samples = 10000\n",
    "points_small = points[np.random.choice(points.shape[0], n_samples, replace=False)]\n",
    "fake_small = fake[np.random.choice(fake.shape[0], n_samples, replace=False)]\n",
    "swd_fs_small = ot.sliced_wasserstein_distance(points_small, fake_small)\n",
    "print(f\"Sliced Wasserstein distance between FS and random: {swd_fs_small:.5f};\\t Difference: {swd_fs_small-swd_fs:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1df36ea6e94e05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-21T02:47:55.405061Z",
     "start_time": "2024-05-21T02:47:55.402893Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "convGAN",
   "language": "python",
   "name": "convgan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
